池化技术：
malloc本身也是个内存池，这个项目比malloc更优（从并发场景下即多线程场景下）
tcmalloc：为了学习tcmalloc，才模拟实现该项目

1.内存池好处：
（1）提高了性能，提高了申请效率
（2）解决了内存碎片（外碎片问题）问题（想要申请一块完整的内存，但是系统中内存都是不连续的）


2.如果一次性给多了内存，则可能不能好好利用。如果一个进程给的太多，其他进程可能申请不到


一次申请大于64K的直接找系统去申请。
（1）thread cache：给每个线程都分配了一个独享的线程池，这样线程在该线程池里申请内存，是不会竞争的线程
                                缓存是每个线程独有的，用于小于64k的内存的分配，线程从这里申请内存不需要加锁，每个
                                线程独享一个cache（无需加锁），这也就是这个并发线程池高效的地方，解决并发的时候性能的问题
（2）central cache：中心缓存是所有线程所共享，thread cache是按需从central cache中获取的对象 
                                central cache周期性的回收thread cache中的对象，避免一个线程占用了太多的内存
                                而其他线程的内存吃紧。达到内存分配在多个线程中更均衡的按需调度的目的。central cache  
                                是存在竞争的，所以从这里取内存对象是需要加锁，不过一般情况下，在这里取内存对象的效率非常高，所以这里竞争不会很激烈。
                                解决了性能问题+高并发  但是没有解决内存碎片问题，解决资源调度问题和内存碎片的前置问题（当一段内存的所有资源都释放回来的时候，会进行合并，不过是合并成一页一页的小span）
（3）page cache：以页为单位，一页4K，页面缓存是central cache缓存上面的一层缓存，存储的内存是以页为单位存储及分配的。
                               central cache没有内存对象时，从page cache分配出一定数量的page，并切割成定长
                               大小快内存，分配给central cache。page cache会回收central cache满足条件的span对象，并且合并相邻的页，组成
                               更大的页，缓解了内存碎片的问题。
page cache 通过brk/sbrk/mmap/munmap（Linux下）、VirtualAlloc(Windows下)以页为单位找系统要内存



外碎片问题：不断向系统申请小块内存，但是还回去只还回去中间的大块，或者其它的，导致内存不连续，然后申请大块内存时，没有。
                     因为内存不连续，导致申请不出大块内存（但是系统此时有的内存总量大于要申请的）




CentralCache
span
{
     pageid; //页号
     _free_list; //自由链表
     use_count; //使用计数
}




定长内存池解决了性能问题，但是没有解决内存碎片问题，但是自身没有内存碎片问题（因为都是定长的）
边长内存池（一定范围内的定长内存池）解决性能问题+应用范围更广的问题，没有解决内存碎片问题
malloc ：解决了性能问题+内存碎片问题，没有解决高并发的malloc
tcmalloc：性能问题+内存碎片问题+高并发


8是8字节 
16是16字节
64KB==》64*1024字节

一个span就是一页，central cache中span总共是一页 8字节下的span是将一页分成8字节的小块共512个



申请的过程：
ThreadCache向CentraCalche申请的过程：    ThreadCache::Allocate() ====》 ThreadCache::FetchFromCentralCache()   ====》 CentralCache::FetchRangObj()     ==== 》如果没有了   CentralCache::GetOneSpan()     
 CentralCache向PageCache申请的过程：        CentralCache::GetOneSpan()     ==== 》如果没有了 PageCache::NewSpan()
PageCache向系统申请内存的过程：               PageCache::SystemAllocPage()

 释放的过程：
ThreadCache释放给CentralCache的过程：    ThreadCache::Dallocate() ====》 ThreadCache::ListToLong() ====》CentralCache::ReleaseListToSpans() 
CentralCache释放给PageCache的过程：        CentralCache::ReleaseListToSpans   ====》  PageCache::ReleaseSpanToPageCache()



和库中的malloc做性能对比的时候开始用debug测试发现，malloc快一点，后来用release下测试发现我们的快
因为库中的malloc在debug中优化之后，会是动态库打成release版的，会比没有优化下的我们的快



性能分析：vs改成debug版：然后点上面的分析中有一个性能探测器，点击，然后点击性能向导然后启动，然后跑完之后就可以看到
代码中哪些指令性能消耗最多，得出结果：ThreadCache::Deallocate消耗性能占了48%左右，PageCache::GetIdToSpan（通过Id找map，
每个对象释放都要通过map去找属于哪个span经常调用）消耗性能占了46%左右（其中.find()这个函数占了46%中的80%，）所以可以对find
进行优化，将map改成unordered_map







项目中的不足：
项目中申请内存还使用了new,new的底层是malloc，所以该项目没有完全脱离malloc
解决方案：
项目中增加一个定长的ObjectPool的对象池，对象池的内存直接使用brk、VirtualAlloc等向系统直接申请



1.有没有用过tcmalloc
   用过，tc_malloc的使用。使用方式和malloc完全一样，将程序中的malloc替换成tcmalloc， 
   使用tcmalloc优化MySQL。
   Linux中：有一个weak.alias机制可以将malloc和free替换成tcmalloc。没有深入了解。void* malloc(size_t size) THROW attribute__ ((alias (tc_malloc)))
   Windows：有一个hook机制可以将malloc和free替换成tcmalloc。



2.讲这个项目====三层





Thread Cache：没有锁的O(1)内存申请和释放。每个线程都可以通过自己的TLS对象无锁的、并发的获取自己的Freelist链表申请内存。
3.能不能将page cache和central cache和central cache合并掉
    不能，因为虽然都是spanList，但是她们spanlist的映射关系是不一样的，也就代表她们凸显的作用不一样
   centralcache里挂的span的页内存是被切成小块按映射关系走的内存对象，有两个作用：一个是均衡多个thread cache
   之间的资源平衡。第二个作用：当span的内存对象都回收回来以后，那么表示pan就可以回收给page cache进行页的合并。
    就可以释放给给page cache合并成一个大页，减少了内存碎片问题，为解决内存碎片问题做了前置准备
    page cache表中挂的span是按照页的大小挂的（1页、2页大小等等）。主要作用：页的分裂分割，页的合并，解决内存碎片问题


4.当线程结束后，线程申请的内存还在thread cache里面，怎么办？
  实现一个destroy_function，会在线程结束的时候调用，就可以去释放thread cache中的内存



项目名称：
项目简介：多线程并发场景下申请内存的效率问题，比malloc在并发场景下效率要高。。。
项目环境以及使用技术：单例模式、C++11、TLS
项目详细介绍



gdb -g test.c -o test
gdb test   启动gdb调试
list 查看源程序代码 默认显示前10行
list [行号n] 查看以n为中签前后10行代码
list [函数名] 查看函数的源代码
run 运行程序到断点处
break [行号]  设置断点
delete [断点号n] 删除第n个断点 
info breakpoints 显示断点信息
continue 继续执行，运行到下一个断点
next 单步执行程序，遇到函数不进入函数
step 单步执行程序，遇到函数会进入函数
quit 退出gdb
watch 设置一个监视点，一旦被监视的表达式值改变了，gdb将停止调试
bt 查看当前调用堆栈


gdb调试多线程
ps-aux | grep a.out //
ps-aL | grep a.out  // 查看当前运行的轻量级进程 

pstack [线程id] 线程栈结构的查看
info threads 查看线程
bt 查看线程栈结构
thread n 切换线程
break 行号/函数名 设置断点
info b 查看断点






















FreeListIndex的计算：
                                                                                                范围内字节数/对齐数
[1byte, 128byte]                                   2^3=8byte对齐            (128-1) / 8=15                15+1=16           freeList[0, 16)
[129byte, 1024byte]                             2^4=16byte对齐          (1024-129)/16=56          56+16=72         freeList[16, 72)
[1025byte, 8*1024=8192byte]             2^7=128byte对齐        (8192-1025)/128=56      72+56=128       freeList[72, 128)
[8193byte, 64*1024=65536byte]         2^10=1024byte对齐    (65536-8193)/1024=56  56+128=184     freeList[128, 184)



ThreadCache向CentralCache申请内存：先要RoudUp(size)，然后再NumMoveSize(size)一下
ThreadCahce向CentralCache释放内存：要NumMoveSize(size)一下用来判断freelist对应的index下的对象个数是否已满
CentralCache向PageCache申请内存：先要NumMovePage(size)计算申请的内存大小是多少页，最少为一页

基数树，是将long整数和指针键值相关联的机制，它存储有效率，并且可以快速查询，用于整数和指针的映射

1. 对于长整形的映射，如何解决hash冲突和Hash表的设计，基数树可以根据一个长的整形快速查找到对象的指针， 比hash简单，而且更加节省空间。
2. 基数树的空间使用更加灵活，只有当需要用到某个节点时，才会创建
根据长整形比如 1001010010 0是左孩子 1是右孩子 继续向下创建节点。当然如果深度够深的话，那么还需要将每一个节点使用2位数字表示 00 01 02
如果频繁的malloc吃不消的话， 还可以先开一个内存池，在内存池中申请 节点空间进行 映射使用， 而且查询效率也是O(lgn)的

线程TLS 线程的局部存储 用来将数据与一个正在执行的指定线程关联起来


ListIndex(size) 算出size对应的freeList链表的下标

malloc基本的实现原理就是维护一个内存空闲链表，当申请内存空间时，
搜索内存空闲链表，找到适配的空闲内存空间，然后将空间分割成两个内存块，
一个变成分配块，一个变成新的空闲块。如果没有搜索到，那么就会用sbrk()才推进brk指针来申请内存空间。



 